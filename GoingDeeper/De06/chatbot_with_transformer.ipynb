{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e69c38f",
   "metadata": {},
   "source": [
    "## 프로젝트 목표\n",
    "---\n",
    "1. 챗봇 훈련데이터 전처리 과정이 체계적으로 진행되었는가?\n",
    "    * 챗봇 훈련데이터를 위한 전처리와 augmentation이 적절히 수행되어 3만개 가량의 훈련데이터셋이 구축되었다.\n",
    "2. transformer 모델을 활용한 챗봇 모델이 과적합을 피해 안정적으로 훈련되었는가?\n",
    "    * 과적합을 피할 수 있는 하이퍼파라미터 셋이 적절히 제시되었다.\n",
    "3. 챗봇이 사용자의 질문에 그럴듯한 형태로 답하는 사례가 있는가?\n",
    "    * 주어진 예문을 포함하여 챗봇에 던진 질문에 적절히 답하는 사례가 제출되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20741a7b",
   "metadata": {},
   "source": [
    "### 라이브러리 확인\n",
    "---\n",
    "* models.py을 이용해 transformer class 구현\n",
    "* utils.py을 이용해 데이터 전처리에 필요한 함수 및 기타 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f706838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sentencepiece as spm\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import gensim\n",
    "import pickle\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *\n",
    "from models import Transformer, Encoder, Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1b0fcccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU 활성화됨: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# GPU가 사용 가능한 경우, 기본 디바이스를 GPU로 설정\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')  # 첫 번째 GPU만 사용\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)  # 필요할 때만 GPU 메모리 사용\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "print(\"✅ GPU 활성화됨:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8fc4f1",
   "metadata": {},
   "source": [
    "## 데이터 처리\n",
    "\n",
    "### 데이터 다운로드\n",
    "---\n",
    "1. ChatbotData .csv\n",
    "2. csv 파일을 읽는 데에는 pandas 라이브러리\n",
    "3. 읽어 온 데이터의 질문과 답변을 각각 questions, answers 변수에 나눠서 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "66bf07ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.getenv('HOME') + \"/aiffel/transformer_chatbot/data/\"\n",
    "df = pd.read_csv(file_path+\"ChatbotData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "14ebe361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "699d4302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q        0\n",
       "A        0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4121739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['label']) # 'label' 열 제거\n",
    "df = df.drop_duplicates() # 중복 데이터 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0af2b31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of chatbot data:  11750\n"
     ]
    }
   ],
   "source": [
    "print('the number of chatbot data: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6f455ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>커피 볶는 시간</td>\n",
       "      <td>커피향 좋겠어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>뭐 해주기가 싫어</td>\n",
       "      <td>상처받았나봐요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>눈물만.</td>\n",
       "      <td>지금은 우세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>내 주제를 모르고 덤빈건가</td>\n",
       "      <td>그건 아닐 거예요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>중2병</td>\n",
       "      <td>힘들 때네요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Q           A\n",
       "0        커피 볶는 시간   커피향 좋겠어요.\n",
       "1       뭐 해주기가 싫어    상처받았나봐요.\n",
       "2            눈물만.    지금은 우세요.\n",
       "3  내 주제를 모르고 덤빈건가  그건 아닐 거예요.\n",
       "4             중2병     힘들 때네요."
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train / test split 전에 무작위 shuffle\n",
    "df = df.sample(frac=1).reset_index(drop=True) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5189e2a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 데이터 정제\n",
    "---\n",
    "**utils.py** 파일에 아래 두 조건으로 **preprocess_sentence 함수 구현**\n",
    "\n",
    "1. 영문자의 경우, ***모두 소문자로 변환***합니다.\n",
    "2. 영문자와 한글, 숫자, 그리고 주요 특수문자를 제외하곤 ***정규식을 활용***하여 모두 ***제거***합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c94edf",
   "metadata": {},
   "source": [
    "### 데이터 토큰화\n",
    "---\n",
    "**utils.py** 파일에 아래 두 조건으로 **build_corpus 함수 구현**\n",
    "\n",
    "1. ***소스 문장 데이터***와 ***타겟 문장 데이터***를 입력으로 받습니다.\n",
    "2. 데이터를 앞서 정의한 ***preprocess_sentence() 함수로 정제하고, 토큰화***합니다.\n",
    "3. 토큰화는 ***전달받은 토크나이즈 함수***를 사용합니다. 이번엔 ***mecab.morphs 함수***를 전달하시면 됩니다.\n",
    "4. 토큰의 개수가 일정 길이 이상인 문장은 데이터에서 제외합니다.\n",
    "5. ***중복되는 문장은 데이터에서 제외***합니다. 소스 : 타겟 쌍을 비교하지 않고 소스는 소스대로 타겟은 타겟대로 검사합니다. 중복 쌍이 흐트러지지 않도록 유의하세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "38efc7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test split\n",
    "test_len = len(df) // 10\n",
    "\n",
    "que_corpus_train = df[\"Q\"][:-test_len]\n",
    "que_corpus_test = df[\"Q\"][-test_len:]\n",
    "\n",
    "ans_corpus_train = df[\"A\"][:-test_len]\n",
    "ans_corpus_test = df[\"A\"][-test_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "906ae9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10575\n",
      "10575\n",
      "1175\n",
      "1175\n"
     ]
    }
   ],
   "source": [
    "que_corpus_train = build_corpus(que_corpus_train)\n",
    "que_corpus_test = build_corpus(que_corpus_test, is_train=False) # test data에는 전처리만 진행\n",
    "\n",
    "ans_corpus_train = build_corpus(ans_corpus_train)\n",
    "ans_corpus_test = build_corpus(ans_corpus_test, is_train=False)\n",
    "\n",
    "print(len(que_corpus_train))\n",
    "print(len(ans_corpus_train))\n",
    "print(len(que_corpus_test))\n",
    "print(len(ans_corpus_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "13e95c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 질문 문장 길이 :  32\n",
      "최소 질문 문장 길이 :  1\n",
      "평균 질문 문장 길이 :  7.033286052009457\n"
     ]
    }
   ],
   "source": [
    "# 문장 길이 분석하기\n",
    "print(\"최대 질문 문장 길이 : \", max(len(x) for x in que_corpus_train))\n",
    "print(\"최소 질문 문장 길이 : \", min(len(x) for x in que_corpus_train))\n",
    "print(\"평균 질문 문장 길이 : \", sum(map(len, que_corpus_train))/len(que_corpus_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fba52a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 대답 문장 길이 :  40\n",
      "최소 질문 문장 길이 :  1\n",
      "평균 대답 문장 길이 :  8.382978723404255\n"
     ]
    }
   ],
   "source": [
    "print(\"최대 대답 문장 길이 : \", max(len(x) for x in ans_corpus_train))\n",
    "print(\"최소 질문 문장 길이 : \", min(len(x) for x in ans_corpus_train))\n",
    "print(\"평균 대답 문장 길이 : \", sum(map(len, ans_corpus_train))/len(ans_corpus_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da178791",
   "metadata": {},
   "source": [
    "### Augmentation\n",
    "---\n",
    "***Lexical Substitution을 실제로 적용***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5d19dfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.84295124 -0.59497476 -0.06958017  0.22912623 -1.6996183   2.8055239\n",
      "  0.3761203  -2.6914809  -3.5348327  -1.8608217   0.18685858  0.08781391\n",
      " -1.5988438  -0.50004035  1.5011966   2.3389707  -2.1298397   2.3418503\n",
      "  4.9678206  -2.016749   -1.60092    -1.0502566   0.6944076   1.3268162\n",
      "  4.023851   -0.54679507  1.8050268  -0.34493855  0.15280624 -4.112347\n",
      " -0.7641386   0.8001268  -5.7092285   2.3291602   2.6685705   1.2506164\n",
      " -0.9265311  -1.4639043   1.0062082   0.95739704  2.1613991  -5.3201756\n",
      "  4.1486487   0.7119045  -0.44255644  1.9117382   2.0401163   1.2536596\n",
      " -3.4907508   2.5135577   0.0192101   0.13117276  1.9888952   0.61847246\n",
      " -2.254515   -1.8180193  -0.01343717 -1.0221493   2.9350507  -2.5792298\n",
      "  2.09504     2.306522    0.82577235 -3.3861275  -2.3184435  -2.7063618\n",
      " -0.20487231  0.6776788  -2.3545253  -1.3137537  -3.0127792  -0.6701537\n",
      " -2.089253    1.3784735  -4.1710854  -3.7226741   3.1941407  -3.574488\n",
      "  0.3274521  -3.5230722  -2.13166     4.005327    0.7389973   0.92136264\n",
      " -3.953086   -1.0276546   2.0271258  -1.3101991   4.024926    1.638781\n",
      "  3.0503814  -1.3031713   0.533933   -1.7324414  -1.3113374  -0.18669418\n",
      "  3.1186237   1.4850899   4.5497875   1.9276507 ]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "file_path = os.getenv('HOME') + \"/aiffel/transformer_chatbot/data/\"\n",
    "# Word2Vec 모델 로드\n",
    "ko_vec = Word2Vec.load(file_path + 'word2vec_ko.model')\n",
    "\n",
    "# 모델 테스트: 특정 단어의 벡터 확인\n",
    "word_vector = ko_vec.wv[\"단어\"]  # \"단어\"의 벡터\n",
    "print(word_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4da3de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_sub(src, wv, ratio=0.5):\n",
    "    result = []\n",
    "    for tok in src:\n",
    "        # 확률적으로 단어를 바꿀지 말지를 결정\n",
    "        if tok in wv and random.random() < ratio:\n",
    "            similar_words = wv.most_similar(tok, topn=1)  # 단어를 입력으로 사용\n",
    "            result.append(similar_words[0][0] if similar_words else tok)\n",
    "        else:\n",
    "            result.append(tok)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0de22490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "산기슭 은   산기슭 이 고   물 은   바닷물 이 다   .\n"
     ]
    }
   ],
   "source": [
    "src = '산은 산이고 물은 물이다 .'\n",
    "\n",
    "print(\" \".join(lexical_sub(src, ko_vec.wv, ratio=0.3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b50552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_que_corpus_train = []\n",
    "\n",
    "for old_src in que_corpus_train:\n",
    "    new_src = lexical_sub(old_src, ko_vec.wv, ratio=0.3)\n",
    "    aug_que_corpus_train.append(new_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25d875e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle로 저장\n",
    "f_aug_que_corpus_train = open(\"aug_que_corpus_train.pickle\",\"wb\")\n",
    "pickle.dump(aug_que_corpus_train,f_aug_que_corpus_train)\n",
    "f_aug_que_corpus_train.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6528f161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle로 로딩\n",
    "f_aug_que_corpus_train = open(\"aug_que_corpus_train.pickle\",\"rb\")\n",
    "aug_que_corpus_train = pickle.load(f_aug_que_corpus_train)\n",
    "f_aug_que_corpus_train.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "779e9d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['커피 볶 는 시간', '뭐 해 주 기 가 싫 어', '눈물 만 .', '내 주제 를 모르 고 덤빈 건가', '중 2 병', '상황 이 어찌 됐 던 간 에 내 가 못 잊 겠 으면 연락 을 했 겠 죠 .', '보 고 싶 다고 하 네', '결국 연락 했 어', '남자 가 여자 를 좋아할 때 하 는 행동 이 뭐 가 있 나요 ?', '다 들 어떠셨 어 ? 결국 이렇게 되 는 건가', '일찍 퇴근 하 고 쉬 고 있 어', '너 이러 면 미워한다', '사랑니 나 나 봐', '너무 사랑 했 고 너무 그리워 하 는 그 사람 .', '과거 의 나 한테 화나', '전화 걸어도 되 나', '나 를 보 는 거 같 아', '금연 이 쉽 지 않 아', '쉬 고 싶 다', '기댈 수 있 는 사람', '행운 을 빌 어 줘', '대화 가 잘 통하 는 사람 이 야', '핸드폰 중독 인 듯', '로또 번호 알려줘', '마지막 사랑', '헤어진 건가 이거 ?', '길 에서 번호 따 였 어', '살며시 다가왔 어', '마음 에 하나 도 안 들 어', '일 주일 이 너무 길 어', '헤어진지 1 달 정도 되 었 습니다', '이용 만 당했 던 건가', '지갑 없 어 졌 어', '밤 에 잠 이 안 와', '내 욕심 일 뿐 이 지', '한 번 의 기회 쯤 있 겠 지 라고 생각 했 던 내 생각 이 어리석 었 습니다', '미워한다', '술병 이 네', '짝 녀 프 사 자음 이 궁금 함 .', '여자 친구 가 너무 좋 은데 점 본 거 에서 는 만나 지 말 래 .', '헤어 진지 한 달째', '데이트 통장 만들 까 ?', '낙엽 밟 는 소리 좋 다', '첫 눈 에 반하 는 게 가능 해 ?', '술 이 야', '짧 은 시간 이 었 다 .', '헤어졌 어 .', '이별 후 그 사람 과 마주치 는 거', '자기 도 해결 방안 이 없 으면서 불만 만해', '여자 친구 와 의 헤어짐 을 막 고 싶 어', '자전거 데이트 어떨까 ?', '정말 왜 이러 는 걸까', '어제 헤어진 여친 학교 다녀 왔 어 .', '나 를 떠보 는 것 같 은 짝 남 .', '선물 로 인형 받 았 어', '스스로 에게 너무 인색 했 네', '어떻 해야 할까', '결혼 한 지 1 년 됐 는데 넘 좋아', '먹 는 거 에 너무 예민 한 여자 친구 가 고민 임 .', '일 만 하 고 살 았 는데 이 모양', '스트레스 푸 는 방법', '구걸 하 듯 사랑 하 지 마', '먼지 가 쌓였 네', '교양 듣 는 데 심 남 있 음 . 썸 타 고 싶 다 .', '오랜만 에 아침 먹 었 어', '보 고 싶 어 잠 이 안 와', '더워서 죽 을 듯 한 날씨 야', '비 오 는데 ?', '연락 하 고 지내 는데', '편해 지 는 게 당연 한 데 속상해 .', '안경테 뭐 로 바꿀까', '어제 그녀 를 또 보 았 어 .', '일 은 원래 혼나 면서 배워 ?', '잘 나갈 때 은퇴 해야 하나 ?', '나쁜 마음 이 듭니다 .', '이별 할 때 지켜야 할 매너', '인생 너무 불공평 해', '친구 들 이랑 노래방 가 고 싶 어', '한숨', '인턴 됐 어', '오늘 꿈 에 는 짝 남 이 나왔 으면 .', '짝 녀 에게 내 옷 좀 봐 달 라고 만나 자 해도 될까 ?', '앞 으로 어떻게 살 지 ?', '생각 만 해도 마음 이 무거워', '취업 하 기 힘들 겠 지 ?', '어찌 해야 할까', '부모 님 처럼 살 고 싶 다', '오늘 밤 하 고 픈 말 다 쏟 아 내려 합니다 !', '남편 이 맨날 늦 게 들어와', '딸기 먹 어야지', '좋 아 하 는 사람 이 거짓말 을 하 면 어떡 하 죠 .', '이젠 어떡 해얄 지 모르 겠 어', '헤어진 남친 의 sns 행적', '나 왕따 야', '좋 아 하 는 사람 이 카톡 차단 한 듯 .', '행복 은 어디 있 어 ?', '가스 비 비싼데 감기 걸리 겠 어', '헤어진 사람 에게 잊 는 동안 도움 은 못 받 겠 죠 ?', '오늘 도 한숨 만 쉬 다 하루 다 갔 네', '명품 선물 꼭 해야 할까 ?', '오늘 백 일 이 야', '썸남 이 짝 남 됐 어요 . 위로 해 주 세요 .', '눈물 이 말랐 는지 슬퍼도 감정 이 안 나오 네', '아 오늘 힘드 네', '소중 한 것 을 .', '심각 합니다 .', '보 기 만 해도 짜증 이 나 지', '헤어진지 한 달 짼데']\n",
      "['내 가 너무 진지 해진 걸까 .', '오래 헤어지 고 방식 어서 헤어진 남자 에게 때문 후폭풍 없 나 /', '바람난 건가 ?', '이별 은 왤케 어려우므로 나', '보험 많이 들 었었 어', '요즘 자꾸 깜빡깜빡 해', '눈물 나 서 못 늦추 셨 어서', '소소 한 걸로 트집 잡 는 사람 어떡 해서 /', '투쟁 봐도 살 은 안 빠져', '오늘 은 내 이 표정 은 가 괜찮 아', '연애 은 어떻게 시키 는 건가 니라', '안경테 바꿀까 우린', '나이 가 많 을수록 이직 이 될까', '취업 가 면 좋 셨 당치도', '동거 은 하 고자 싫 은데 썸 은 타 는데 싶 어서 \"', '노처녀 이 사진 잘 찍 었 으면', '남자 연인 가 첫 이별 이 야', '몇 일 직전 그 사람 보여졌 어', '내일 일찍 일어나 니라 돼', '외제 차 갖 고 싶 다', '사귀 는 거 잘 시키 은 여인 들 부러워', '공부 시키 기 싫 어', '헤어진 뒤 거의 세 열흘 이 되 어 가 네', '정말 끼치 겠 네', '배구 시키 다 무르팍 깨뜨리 잭', '눈물 이상 .', '사인회 할까 말 까', '여인 은 다른 것 연애 은 비슷 해', '으휴 집 에 들어가 기 가 싫 네', '나 잘 시키 은 도록 있 어', '그 사람 이 나 을 찾 았 으면 괜찮 겠 어서', '내일 소풍 간다', '정규직 시키 고 싫 다', '단 둘 이 놀 자', '미련 스럽 는데', '연애 하 고 나 이상 살 쪘 나 우린', '출퇴근 시간 너무 오래 걸려 .', '내 성품 너무 소심 해', '해진 번 보 는데 무엇 생각 하 지', '짝 남 이 굉장히 좋 을수록 패션 센스 가 별로 야 \"', '나가 확신 껴 몇몇 여인 확신 은 진짜 달랐 다는 내밀 느껴', '바닷속 이 안 좋 아', '사귄 것 일까 아닌 것 인가', '도와 줘 .', '이런 제 이 싶 어', '반드시 빼앗 고 싶 어요', '매듭 남매 가 학교 에서 소문 이 안 괜찮 아 .', '짝사랑', '같 는 하늘 다른 평면', '자기 말 은 상상 못하 시키 고 나 만 혼내 은 여인 어떡 해 /', '클럽 이 고 싶 은데 말 하 고 갈까', '최치원전 한 고레섬 갖 는데 싶 다', '직전 여자 친구 부친상 다녀왔 어', '아기 기르 는 거 너무 어려울 것 같 아', '애기 가 밥 을 너무 안 먹 어서', '헤어진지 1 달째 됐 습니다 .', '언젠가 은 끝', '두 열흘 간 에 연애 그리고 헤어짐', '너 오늘 내 가 채웠 어', '레고 사 고 싶 은데 비싸', '이렇게 얘기 라도 시키 면 나 아서 질까 ? \"', '실체 가 안 된다', '남편 은 자꾸 만져', '헤어지 고 든 서부터 다시 붙잡 길래 믿 었 어 \"', '여자 언제 서 만나', '친구 결혼식 에서 피로연 준비 가운데', '사랑 하 은 사람 는 표시 가 없 었었 으면 좋 겠 다', '이별 후 후회 , 아쉬움', '남편 이 실컷 늦 도록 들어와', '寫眞', '조심 할 게 많 아', '떠나간 사람 은 이렇게 도 차갑 나 ?', '내 가 너무 이기 적 이 었 어', '멍멍 핸 라이히 번호 기억 못 하 나 ?', '맘 늘어놓 고 후회 할 곳 이 없 네 .', '그런 친구 아니 었 는데 굉장히 귀찮 도록 하 네', '다시 불안 .', '유보 준비 하 는 것 연애 하 면 앞 된 셨 지 ?', '영화 보 는데 왔 는데', '한 차례 의 성과 쯤 있 셨 지 라고 생각 했 던 내 생각 이 어리석 었 습니다', '하늘 증간 이 언젠지', '짝 남 와 자연 스러운 게 친해질 수 있 는 방식 있 을까 /', '친구 랑 나 랑 자꾸 대조 하 게 돼', '쯤 학비 이 없 어', 'sns 보 려면 나 이상 때리 는데 다 행복 해 가져다', '남자 친구 랑 스킨십 하 고 싶 어', '이별 은 필수 아닙니다', '남자 가 고기잡이 를 너무 괜찮 아 해', '아빠 아빠 랑 곧바로 똑같이 남 아야 돼', '어디 서부터 맛난 냄새 가 나 는데', '오늘 은 또 무엇 버티 지 /', '든 너 에게 다시 돌아가 려면 돌려받 아서 줄 까 야 ? ? 라는 생각 \"', '나가 가 바보 당치도', '쉬 마려', '엄마 어렵 게 했 어서', '내일 치장 이 앞 먹 어', '사랑 시키 는 사람 와 아침 을 함께 맞이 하 는데 싶 어서', '혼자 좋아하 는 줄거리 .', '힘들 어 죽 을 거 같 습니다', '부모 님 반대 설득 하 고 싫 어서', '매듭 남 도 에서 영혼 이 어리광 어떻게 해야 할지 모르 겠 어 \"', '어린애 같 은 마음 .', '이런 사람 를 만나 는데 싫 네', '바닷물 은 안 나와', '대략 먹 었 더니 매어', '예식장 취소 했 어', '사랑 한 지 3 개월', '든 회사 의 인정받 는데 싶 어']\n"
     ]
    }
   ],
   "source": [
    "print([\" \".join(sample) for sample in que_corpus_train[:108]])\n",
    "print([\" \".join(sample) for sample in aug_que_corpus_train[:108]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "51452fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31725\n"
     ]
    }
   ],
   "source": [
    "augmented_que_train = que_corpus_train + aug_que_corpus_train + que_corpus_train\n",
    "print(len(augmented_que_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c189b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_ans_corpus_train = []\n",
    "\n",
    "for old_src in ans_corpus_train:\n",
    "    new_src = lexical_sub(old_src, ko_vec.wv, ratio=0.3)\n",
    "    aug_ans_corpus_train.append(new_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "efab1138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle로 저장\n",
    "f_aug_ans_corpus_train = open(\"aug_ans_corpus_train.pickle\",\"wb\")\n",
    "pickle.dump(aug_ans_corpus_train,f_aug_ans_corpus_train)\n",
    "f_aug_ans_corpus_train.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "60d66dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle로 로딩\n",
    "f_aug_ans_corpus_train = open(\"aug_ans_corpus_train.pickle\",\"rb\")\n",
    "aug_ans_corpus_train = pickle.load(f_aug_ans_corpus_train)\n",
    "f_aug_ans_corpus_train.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "638e82c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31725\n"
     ]
    }
   ],
   "source": [
    "augmented_ans_train = ans_corpus_train + ans_corpus_train + aug_ans_corpus_train \n",
    "print(len(augmented_ans_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b346cfb6",
   "metadata": {},
   "source": [
    "### 데이터 벡터화\n",
    "---\n",
    "1. 타겟 데이터인 ans_corpus 에 <start> 토큰과 <end> 토큰이 추가\n",
    "2. 소스 데이터와 타겟 데이터가 같은 언어를 사용\n",
    "3. ans_corpus 또한 완성이 되었으니, que_corpus 와 결합하여 전체 데이터에 대한 단어 사전을 구축\n",
    "4. 벡터화하여 enc_train 과 dec_train 데이터 셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1112e84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <start>와 <end> 토큰을 ans_corpus에 추가\n",
    "augmented_ans_train = [['<start>'] + sentence + ['<end>'] for sentence in augmented_ans_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8bc96d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# que_corpus와 ans_corpus 결합하여 단어 사전 생성\n",
    "combined_corpus = augmented_que_train + augmented_ans_train\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(combined_corpus)\n",
    "\n",
    "# 각 문장을 정수 시퀀스로 변환\n",
    "enc_train = tokenizer.texts_to_sequences(augmented_que_train)\n",
    "dec_train = tokenizer.texts_to_sequences(augmented_ans_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "63428d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31725, 40)\n",
      "(31725, 40)\n"
     ]
    }
   ],
   "source": [
    "# 패딩 추가\n",
    "max_len = 40\n",
    "\n",
    "enc_train = tf.keras.preprocessing.sequence.pad_sequences(enc_train, \n",
    "                                                          maxlen=max_len,\n",
    "                                                         padding='post')\n",
    "dec_train = tf.keras.preprocessing.sequence.pad_sequences(dec_train, \n",
    "                                                          maxlen=max_len,\n",
    "                                                         padding='post')\n",
    "\n",
    "print(enc_train.shape)\n",
    "print(dec_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a56a64f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train, enc_val, dec_train, dec_val = train_test_split(enc_train, dec_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ff527682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28552, 40) (28552, 40)\n",
      "(3173, 40) (3173, 40)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).batch(batch_size=BATCH_SIZE)\n",
    "val_data = tf.data.Dataset.from_tensor_slices((enc_val, dec_val)).batch(batch_size=BATCH_SIZE)\n",
    "\n",
    "print(enc_train.shape, dec_train.shape)\n",
    "print(enc_val.shape, dec_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7466100",
   "metadata": {},
   "source": [
    "## 훈련하기\n",
    "---\n",
    "앞서 번역 모델을 훈련하며 정의한 Transformer 를 그대로 사용하시면 됩니다! 대신 데이터의 크기가 작으니 하이퍼파라미터를 튜닝해야 과적합을 피할 수 있습니다. 모델을 훈련하고 아래 예문에 대한 답변을 생성하세요! 가장 멋진 답변과 모델의 하이퍼파라미터를 제출하시면 됩니다.\n",
    "\n",
    "<div>\n",
    "    \n",
    "    # 예문\n",
    "    1. 지루하다, 놀러가고 싶어.\n",
    "    2. 오늘 일찍 일어났더니 피곤하다.\n",
    "    3. 간만에 여자친구랑 데이트 하기로 했어.\n",
    "    4. 집에 있는다는 소리야.\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    # 제출\n",
    "    \n",
    "    Translations\n",
    "    > 1. 잠깐 쉬 어도 돼요 . <end>\n",
    "    > 2. 맛난 거 드세요 . <end>\n",
    "    > 3. 떨리 겠 죠 . <end>\n",
    "    > 4. 좋 아 하 면 그럴 수 있 어요 . <end>\n",
    "    \n",
    "    Hyperparameters\n",
    "    > n_layers: 1\n",
    "    > d_model: 368\n",
    "    > n_heads: 8\n",
    "    > d_ff: 1024\n",
    "    > dropout: 0.2\n",
    "    \n",
    "    Training Parameters\n",
    "    > Warmup Steps: 1000\n",
    "    > Batch Size: 64\n",
    "    > Epoch At: 10\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0662c877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, (2*(i//2)) / np.float32(d_model))\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "\n",
    "    return sinusoid_table\n",
    "\n",
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_lookahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_enc_mask = generate_padding_mask(src)\n",
    "\n",
    "    dec_lookahead_mask = generate_lookahead_mask(tgt.shape[1])\n",
    "    dec_tgt_padding_mask = generate_padding_mask(tgt)\n",
    "    dec_mask = tf.maximum(dec_tgt_padding_mask, dec_lookahead_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "        \n",
    "\n",
    "    def split_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        split_x = tf.reshape(x, (bsz, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (bsz, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "\n",
    "    \n",
    "    def call(self, Q, K, V, mask):\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "        \n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "        \n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask)\n",
    "                        \n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "            \n",
    "        return out, attention_weights\n",
    "\n",
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "\n",
    "        self.fc1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "            \n",
    "        return out\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, enc_attn\n",
    "\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "    \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        '''\n",
    "        Masked Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        # Q, K, V 순서에 주의하세요!\n",
    "        out, dec_enc_attn = self.enc_dec_attn(Q=out, K=enc_out, V=enc_out, mask=dec_enc_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn\n",
    "\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "    \n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "    \n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        \n",
    "        return out, enc_attns\n",
    "\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "                            \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        out = x\n",
    "    \n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, dec_enc_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns\n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    src_vocab_size,\n",
    "                    tgt_vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout=0.2,\n",
    "                    shared_fc=True,\n",
    "                    shared_emb=False):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        if shared_emb:\n",
    "            self.enc_emb = self.dec_emb = \\\n",
    "            tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        else:\n",
    "            self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "            self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared_fc = shared_fc\n",
    "\n",
    "        if shared_fc:\n",
    "            self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared_fc: out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.do(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "        \n",
    "    def call(self, enc_in, dec_in, enc_mask, dec_enc_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "        \n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, dec_enc_mask, dec_mask)\n",
    "        \n",
    "        logits = self.fc(dec_out)\n",
    "        \n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8158efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 20000\n",
    "BATCH_SIZE = 256\n",
    "D_MODEL = 512\n",
    "\n",
    "transformer = Transformer(\n",
    "    n_layers=5,\n",
    "    d_model=D_MODEL,\n",
    "    n_heads=8,\n",
    "    d_ff=1024,\n",
    "    src_vocab_size=VOCAB_SIZE,\n",
    "    tgt_vocab_size=VOCAB_SIZE,\n",
    "    pos_len=max_len,\n",
    "    dropout=0.3,\n",
    "    shared_fc=True,\n",
    "    shared_emb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8f0af786",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "238e62cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = LearningRateScheduler(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                        epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "8d221ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ad40a38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    tgt_in = tgt[:, :-1]  # Decoder의 input\n",
    "    gold = tgt[:, 1:]     # Decoder의 output과 비교하기 위해 right shift를 통해 생성한 최종 타겟\n",
    "\n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt_in)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt_in, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "68a17ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def eval_step(src, tgt, model):\n",
    "    tgt_in = tgt[:, :-1]  # Decoder의 input : end 토큰 제외\n",
    "    gold = tgt[:, 1:]     # Decoder의 output : start 토큰 제외\n",
    "\n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt_in)\n",
    "\n",
    "    # 그래디언트를 계산하지 않음\n",
    "    predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt_in, enc_mask, dec_enc_mask, dec_mask)\n",
    "\n",
    "    # 손실 계산\n",
    "    loss = loss_function(gold, predictions)\n",
    "\n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "05a5b754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154f78eaaef54b0ca839a5f17ee4d2f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 07:04:03.456737: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c47a69535a4146af725ebc969e73d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training Loss: 7.8312, Validation Loss: 5.5839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 07:04:07.178224: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c6d32884e1f47b5b6fe81764cb02f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 07:04:49.459316: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072d773dd362463ba0d00b3af2f1b78c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training Loss: 5.1466, Validation Loss: 4.8536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 07:04:50.353081: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b926d05a12d4f7eb0633cbfe4ef4507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 07:05:32.620372: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb75f59c0524a349e2f805e8c81375d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training Loss: 4.4985, Validation Loss: 4.2519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 07:05:33.532031: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9580cb35e4d14803a05eeeaf009c7def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 07:06:16.056675: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b10d2fb086432e83202853ed788ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Training Loss: 3.8768, Validation Loss: 3.8109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 07:06:16.957021: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff271fe8d8f415d8dbda59c83b07699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 07:07:00.005948: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577feb1453ca482e85c6fd271c0894c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Training Loss: 3.4402, Validation Loss: 3.5758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 07:07:00.868134: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919a534dd8c34759afa78f459f774392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 07:07:44.074199: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99e979774fb4802b3c3db46f9b58a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Training Loss: 3.0897, Validation Loss: 3.4441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 07:07:44.986468: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2aa2f42c3d34111880bba53a59699da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 07:08:28.127171: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8145ee4eeac94b47b53d490c263f2bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Training Loss: 2.7373, Validation Loss: 3.4184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 07:08:29.013609: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da46ab75cb494b0c9a5bdc8feb62cff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 07:09:12.151462: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa81a0d1bd1443aaaeff8a872e557154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Training Loss: 2.3580, Validation Loss: 3.5010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 07:09:13.050127: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c7b750b3a84ebbac114cd8f7be18e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 07:09:56.203806: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ae1ed00f9c47d6b28f5895c9ffc803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Training Loss: 1.9752, Validation Loss: 3.6044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 07:09:57.046081: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d14c06f1ec8f4a928583d8fb6f20f1fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 07:10:40.170012: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077a409a38824e46b94611390a3ea332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Training Loss: 1.6154, Validation Loss: 3.7574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 07:10:41.065212: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "train_losses = []  # 학습 손실을 저장할 리스트\n",
    "eval_losses = []   # 평가 손실을 저장할 리스트\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    total_eval_loss = 0  # 평가 손실을 저장할 변수\n",
    "\n",
    "    # 훈련 데이터에 대해 학습\n",
    "    dataset_count = tf.data.experimental.cardinality(train_data).numpy()\n",
    "    tqdm_bar = tqdm(enumerate(train_data), total=dataset_count)\n",
    "    \n",
    "    for batch, (enc_inputs, dec_inputs) in tqdm_bar:\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "            train_step(enc_inputs, dec_inputs, transformer, optimizer)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        tqdm_bar.set_description_str(f'Epoch {epoch + 1}')\n",
    "        tqdm_bar.set_postfix_str(f'Loss {total_loss.numpy() / (batch + 1):.4f}')\n",
    "    \n",
    "    train_losses.append(total_loss.numpy() / (batch + 1))  # 학습 손실 기록\n",
    "    \n",
    "    # 평가 단계\n",
    "    eval_dataset_count = tf.data.experimental.cardinality(val_data).numpy()\n",
    "    eval_tqdm_bar = tqdm(enumerate(val_data), total=eval_dataset_count)\n",
    "\n",
    "    for batch, (enc_inputs, dec_inputs) in eval_tqdm_bar:\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "            eval_step(enc_inputs, dec_inputs, transformer)\n",
    "\n",
    "        total_eval_loss += batch_loss\n",
    "\n",
    "        eval_tqdm_bar.set_description_str(f'Epoch {epoch + 1} Validation')\n",
    "        eval_tqdm_bar.set_postfix_str(f'Val Loss {total_eval_loss.numpy() / (batch + 1):.4f}')\n",
    "\n",
    "    eval_losses.append(total_eval_loss.numpy() / (batch + 1))  # 평가 손실 기록\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} - Training Loss: {train_losses[-1]:.4f}, Validation Loss: {eval_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "01cbf53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training / validation loss 시각화\n",
    "plt.plot(range(1, EPOCHS + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, EPOCHS + 1), eval_losses, label='Validation Loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b724dd14",
   "metadata": {},
   "source": [
    "## 성능 측정하기\n",
    "---\n",
    "챗봇의 경우, 올바른 대답을 하는지가 중요한 평가 지표입니다. 올바른 답변을 하는지 눈으로 확인할 수 있겠지만, 많은 데이터의 경우는 모든 결과를 확인할 수 없을 것입니다. 주어진 질문에 적절한 답변을 하는지 확인하고, BLEU Score를 계산하는 calculate_bleu() 함수도 적용해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "940a4105",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS_ID = 2\n",
    "EOS_ID = 3\n",
    "\n",
    "def translate(tokens, model, tokenizer):\n",
    "    # 입력 문장을 패딩\n",
    "    padded_tokens = tf.keras.preprocessing.sequence.pad_sequences([tokens],\n",
    "                                                                  maxlen=max_len,\n",
    "                                                                  padding='post')\n",
    "\n",
    "    ids = []\n",
    "    output = tf.expand_dims([BOS_ID], 0)  # 시작 토큰 추가\n",
    "\n",
    "    for i in range(max_len):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "            generate_masks(padded_tokens, output)\n",
    "\n",
    "        predictions, _, _, _ = model(padded_tokens, \n",
    "                                     output,\n",
    "                                     enc_padding_mask,\n",
    "                                     combined_mask,\n",
    "                                     dec_padding_mask)\n",
    "\n",
    "        predicted_id = tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "        if predicted_id == EOS_ID:  # 종료 토큰이면 중단\n",
    "            return tokenizer.sequences_to_texts([ids])[0]\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    return tokenizer.sequences_to_texts([ids])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e3dae893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answers(sample_questions, model, tokenizer):\n",
    "    responses = []\n",
    "    \n",
    "    for question in sample_questions:\n",
    "        # 입력 문장을 정수 인덱스 시퀀스로 변환\n",
    "        tokens = tokenizer.texts_to_sequences([question])[0]\n",
    "\n",
    "        # 번역(답변 생성)\n",
    "        response = translate(tokens, model, tokenizer)\n",
    "\n",
    "        # 결과 저장\n",
    "        responses.append(response)\n",
    "    \n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "bf12ed85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 지루하다, 놀러가고 싶어.\n",
      "답변: 자연 스러운 감정 은 네요 .\n",
      "\n",
      "질문: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "답변: 데이트 하 면 가능 합니다 .\n",
      "\n",
      "질문: 집에 있는다는 소리야.\n",
      "답변: 자연 스러운 감정 은 네요 .\n",
      "\n",
      "질문: 오늘 일찍 일어났더니 피곤하다.\n",
      "답변: 당신 은 하나 , 당신 , 당신 , 당신 , 가능 하 도록 말 해 보 세요 .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 예문\n",
    "sample_questions = [\"지루하다, 놀러가고 싶어.\",\n",
    "                    \"간만에 여자친구랑 데이트 하기로 했어.\",\n",
    "                    \"집에 있는다는 소리야.\",\n",
    "                    \"오늘 일찍 일어났더니 피곤하다.\"]\n",
    "\n",
    "answers = generate_answers(sample_questions, transformer, tokenizer)\n",
    "\n",
    "for question, answer in zip(sample_questions, answers):\n",
    "    print(f\"질문: {question}\")\n",
    "    print(f\"답변: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28e8853",
   "metadata": {},
   "source": [
    "### BLEU score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "868915c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_bleu_single(model, src_sentence, tgt_sentence, tokenizer, max_len):\n",
    "    src_tokens = tokenizer.texts_to_sequences([src_sentence])[0]\n",
    "    tgt_tokens = tokenizer.texts_to_sequences([tgt_sentence])[0]\n",
    "\n",
    "    # 길이가 max_len을 초과하면 평가하지 않음\n",
    "    if len(src_tokens) > max_len: \n",
    "        return None\n",
    "    if len(tgt_tokens) > max_len: \n",
    "        return None\n",
    "    \n",
    "    # 모델을 사용하여 번역 생성\n",
    "    candidate = translate(src_tokens, model, tokenizer)\n",
    "\n",
    "    # BLEU score 계산\n",
    "    score = sentence_bleu(tgt_sentence, candidate, smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "60ee2c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0056414392419841305\n"
     ]
    }
   ],
   "source": [
    "score = eval_bleu_single(transformer,\n",
    "                         \"오늘 일찍 일어났더니 피곤하다.\",\n",
    "                         \"간만에 여자친구랑 데이트 하기로 했어.\",\n",
    "                         tokenizer,\n",
    "                         max_len)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a29344ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_bleu(model, src_sentences, tgt_sentence, tokenizer, verbose=True):\n",
    "    total_score = 0.0\n",
    "    sample_size = len(src_sentences)\n",
    "    \n",
    "    for idx in range(sample_size):\n",
    "        score = eval_bleu_single(model, src_sentences[idx], tgt_sentence[idx], tokenizer, verbose)\n",
    "        if not score: \n",
    "            continue\n",
    "        \n",
    "        total_score += score\n",
    "    \n",
    "    print(\"Num of Sample:\", sample_size)\n",
    "    print(\"Total Score:\", total_score / sample_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "36d3ac6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Sample: 1175\n",
      "Total Score: 0.0015280364813021134\n"
     ]
    }
   ],
   "source": [
    "eval_bleu(transformer, que_corpus_test, ans_corpus_test, tokenizer, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69da2039",
   "metadata": {},
   "source": [
    "VOCAB_SIZE = 20000\n",
    "BATCH_SIZE = 64\n",
    "D_MODEL = 256\n",
    "\n",
    "transformer = Transformer(\n",
    "    n_layers=2,\n",
    "    d_model=D_MODEL,\n",
    "    n_heads=8,\n",
    "    d_ff=1024,\n",
    "    src_vocab_size=VOCAB_SIZE,\n",
    "    tgt_vocab_size=VOCAB_SIZE,\n",
    "    pos_len=max_len,\n",
    "    dropout=0.3,\n",
    "    shared_fc=True,\n",
    "    shared_emb=True)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.98, \n",
    "                                        epsilon=1e-9)\n",
    " ===>\n",
    "beta 설정 삭제\n",
    "\n",
    "==>\n",
    "BATCH_SIZE = 256\n",
    "D_MODEL = 512\n",
    "==>\n",
    "n_layers=5,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9615eb7b",
   "metadata": {},
   "source": [
    "## 테스트 결과\n",
    "\n",
    "---\n",
    "\n",
    "**기준 설정(epoch:10, BATCH_SIZE = 64, D_MODEL = 256, n_layers=2, n_heads=8, d_ff=1024, dropout=0.3)**\n",
    "\n",
    "![loss](./a_10_l.png)\n",
    "![answer](./a_10_a.png)\n",
    "\n",
    "**제시한 답변 처럼 정확히 나오지 않아 epoch을 30을 하여 훈련 실행 후 결과는 평가 손실이 너무 높게 나오며 더 나쁜 결과 나타냄.**\n",
    "\n",
    "![a_30_l](./a_30_l.png)\n",
    "![a_30_a](./a_30_a.png)\n",
    "\n",
    "**기준 설정에서 optimizer의  beta 옵션 삭제, 평가 손실은 기준 설정과 비슷하나 답변은 안 좋음**\n",
    "\n",
    "![a_30_l](./a_10_Op_l.png)\n",
    "![a_30_a](./a_10_Op_a.png)\n",
    "\n",
    "\n",
    "**위 설정에서  BATCH_SIZE = 256, D_MODEL = 512 수정, 평가 손실은 기준 설정과 비슷하나 답변은 기준 설정과 비슷**\n",
    "\n",
    "![a_10_256_512_l](./a_10_256_512_l.png)\n",
    "![a_10_256_512_a](./a_10_256_512_a.png)\n",
    "\n",
    "\n",
    "**위 설정에서  n_layers=5 수정, 평가 손실은 기준 설정과 비슷하나 답변은 기준 설정과 비슷**\n",
    "\n",
    "![a_10_layer_5_l](./a_10_layer_5_l.png)\n",
    "![a_10_layer_5_a](./a_10_layer_5_a.png)\n",
    "\n",
    "\n",
    "## 결론\n",
    "---\n",
    "**5 epoch 이상의 진행은 손실 함수 지표상 무의한 것으로 보임.**\n",
    "\n",
    "**파라미터, 옵티마이저 설정 변경으로는 기준 설정 이상의 결과가 나오지 않음.**\n",
    "\n",
    "**추후 진행 해 보아야 할 내용**\n",
    "1. 데이타 증가 부분 로직 재 검토\n",
    "2. DLthon시 적용한 google translate api를 이용한 데이타 증강\n",
    "3. wandb를 이용한 옵티마이저 최적화\n",
    "4. mask에 관련된 심화 학습\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17878e72",
   "metadata": {},
   "source": [
    "## 회고\n",
    "\n",
    "트랜스포머 과제 할 때보다 더 깊이 이해 하게 되었으나, 여전히 데이터 처리 관련하여 더 좋은 방법을 찾아야 할 것 같다.\n",
    "\n",
    "beam 서치도 어떻게 적용 할 지 한 번 더 고민 해 보아야 하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f720a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
